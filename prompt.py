"""
@filename:prompt.py
@author:Stmxlt
@time:2025-10-17
"""


import tiktoken
import json
import os
import threading
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

gpt_turbo_encoding = tiktoken.get_encoding("cl100k_base")
MODEL = SentenceTransformer("./local_models/all-MiniLM-L6-v2")
file_lock = threading.Lock()


def json2dict(path):
    with file_lock:
        if not os.path.exists(path):
            raise FileNotFoundError(f"File not found: {path}")
        if os.path.getsize(path) == 0:
            raise ValueError(f"Empty file: {path}")
        try:
            with open(path, "rt", encoding="utf-8") as f:
                content = f.read().strip()
                return json.loads(content) if content else []
        except json.JSONDecodeError as e:
            raise ValueError(f"JSON decode error in {path}: {str(e)}") from e


def dict2json(data, path):
    with file_lock:
        try:
            json_str = json.dumps(data, ensure_ascii=False, indent=2)
            with open(path, "wt", encoding="utf-8") as f:
                f.write(json_str)
        except Exception as e:
            raise ValueError(f"Failed to write JSON to {path}: {str(e)}") from e


def top5_similar(target_id, json_path):
    raw = json2dict(json_path)
    groups = []
    for g in raw:
        if "id" in g and "abstract" in g:
            groups.append({"id": str(g["id"]), "abstract": g["abstract"]})
        else:
            raise ValueError("Missing 'id' or 'abstract' in JSON entry")

    id_to_abs = {g["id"]: g["abstract"] for g in groups}
    target_id = str(target_id)
    if target_id not in id_to_abs:
        raise ValueError(f"ID {target_id} not found")

    target_abs = id_to_abs[target_id]
    others = [g for g in groups if g["id"] != target_id]
    texts = [target_abs] + [g["abstract"] for g in others]
    embs = MODEL.encode(texts, convert_to_tensor=False)
    sims = cosine_similarity([embs[0]], embs[1:])[0]

    scored = [{"id": g["id"], "score": float(s)} for g, s in zip(others, sims)]
    scored.sort(key=lambda x: x["score"], reverse=True)
    return scored[:5]


def top5_ids_only(target_id, json_path):
    return [item["id"] for item in top5_similar(target_id, json_path)]

def truncate_text(text, truncated_length, truncate_type):
    if truncate_type == 'token':
        truncated_encodes = gpt_turbo_encoding.encode(text)[:truncated_length]
        return gpt_turbo_encoding.decode(truncated_encodes)
    elif truncate_type == 'word':
        return ' '.join(text.split(' ')[:truncated_length])

def string2token_nums(string):
    return len(gpt_turbo_encoding.encode(string))


def make_prompt_for_evaluation(examples, target_news, max_tokens=4000):
    evaluation_criteria = """Please evaluate the quality of news articles generated by LLM from news summaries, using human-written news as the standard. Assess from the following aspects and provide revision suggestions:

1. Title requirements:
- Accurately summarize the theme: Whether the title precisely matches the core theme of the news.
- Conciseness: Whether the title is concise, without redundancy, and expresses meaning efficiently.
- Precision of expression: Whether the wording and grammar of the title are accurate, avoiding ambiguity.

2. Lead requirements:
- Closeness to the theme: Whether the lead quickly anchors the core theme of the news.
- Conciseness: Whether the lead uses concise language to introduce information.

3. Body requirements:
- Clarity of theme: Whether the overall text of the body always revolves around the core theme.
- Completeness of information: Whether the body text fully conveys key news information (such as time, location, events and other core elements).
- Clarity of hierarchy: Whether the paragraph division and logical hierarchy of the body text are clear and easy to read.
- Fluency of writing: Whether the sentence connection and expression of the body text are natural and smooth, providing a smooth reading experience.

4. Conclusion requirements:
- Closeness to the theme: Whether the conclusion echoes the theme and effectively concludes the core content.
- Conciseness: Whether the conclusion is concise and powerful, avoiding procrastination and redundancy.

Please refer to the differences between human-written news and LLM news in the following examples, then for the LLM news to be evaluated, provide specific revision suggestions for each of the above aspects."""

    criteria_tokens = string2token_nums(evaluation_criteria)
    example_format = "Example X:\nNews summary:\nHuman-written news:\nLLM news:\n"
    example_format_tokens = string2token_nums(example_format) * len(examples)
    target_format = "News to be evaluated:\nNews summary:\nHuman-written news:\nLLM news:\n"
    target_format_tokens = string2token_nums(target_format)
    total_fixed_tokens = criteria_tokens + example_format_tokens + target_format_tokens

    remaining_tokens = max_tokens - total_fixed_tokens
    if remaining_tokens < 0:
        raise ValueError("Evaluation criteria exceed max token limit")

    per_part_tokens = remaining_tokens // 18
    if per_part_tokens < 10:
        raise ValueError("Insufficient tokens for valid prompt")

    prompt = evaluation_criteria + "\n\n"
    for i, example in enumerate(examples):
        prompt += f"Example{i + 1}:\n"
        abstract = truncate_text(example['abstract'], per_part_tokens, 'token')
        human_news = truncate_text(example['human_news'], per_part_tokens, 'token')

        pre_gpt_news = (example.get("pre_gpt_news") or "").strip()
        machine_news = (example.get("machine_news") or "").strip()
        llm_news = truncate_text(pre_gpt_news if pre_gpt_news else machine_news, per_part_tokens, 'token')
        llm_type = "Previous round GPT result" if pre_gpt_news else "Machine-generated result"

        prompt += f"News summary: {abstract}\n"
        prompt += f"Human-written news: {human_news}\n"
        prompt += f"{llm_type}: {llm_news}\n\n"

    prompt += "News to be evaluated:\n"
    target_abstract = truncate_text(target_news['abstract'], per_part_tokens, 'token')
    target_human = truncate_text(target_news['human_news'], per_part_tokens, 'token')

    target_pre_gpt = target_news.get("pre_gpt_news", "").strip()
    target_machine = target_news.get("machine_news", "").strip()
    target_llm = truncate_text(target_pre_gpt if target_pre_gpt else target_machine, per_part_tokens, 'token')
    target_llm_type = "Previous round GPT result" if target_pre_gpt else "Machine-generated result"

    prompt += f"News summary: {target_abstract}\n"
    prompt += f"Human-written news: {target_human}\n"
    prompt += f"{target_llm_type}: {target_llm}\n\n"

    prompt += "Please provide specific revision suggestions for the above LLM-generated news based on the evaluation criteria."
    return prompt

def make_prompt_for_attacking(examples, target_abstract, target_human_news, json_path):
    human_tokens = string2token_nums(target_human_news)
    human_words = len(target_human_news.split())

    inst1 = f"""You are an expert news writer. Below are examples of high-quality news articles generated from similar summaries, showing benchmark texts, current outputs, and metric comparisons.

    Study these examples carefully, noting:
    - Vocabulary choices that match reference texts (for BLEU/METEOR)
    - Sentence structures and sequence patterns (for ROUGE-L)
    - Semantic accuracy and meaning preservation (for BERTScore)
    - Overall quality and readability (for G-Eval)
    
    Examples:
    {examples}
    """

    inst2 = f"""Generate a news article for the new summary following these specific guidelines:
    
    **CONTENT REQUIREMENTS:**
    1. **Title** (10-15 words): 
       - Include key entities and actions from the summary
       - Mirror vocabulary from the summary when possible
    
    2. **Lead** (2-3 sentences):
       - Reuse important phrases from the summary
       - Answer Who, What, When, Where concisely
       - Maintain similar sentence structure to examples
    
    3. **Body** (3-4 paragraphs):
       - First paragraph: Expand the lead with supporting details
       - Middle paragraphs: Add context, background, and implications
       - Use transitional phrases for coherence
       - Include specific numbers, dates, and quotes when relevant
       - Balance between exact terminology and natural variations
    
    4. **Conclusion** (1-2 sentences):
       - Summarize key impact or future implications
       - Echo the main theme using similar vocabulary
    
    **STYLE GUIDELINES:**
    - Preserve technical terms and proper nouns exactly as in the summary
    - Use synonyms sparingly - prefer consistency with source vocabulary
    - Maintain formal news writing tone throughout
    - Ensure each sentence logically follows the previous one
    - Average sentence length: 15-20 words
    
    **OPTIMIZATION TARGETS:**
    - Vocabulary fidelity: Reuse 60-70% of key terms from the summary
    - Structural consistency: Follow the exemplar patterns shown above
    - Semantic accuracy: All facts must align with the summary
    - Readability: Clear, professional, and engaging
    
    New summary: {target_abstract}
    
    Generate the news article now, ensuring high overlap with summary vocabulary while maintaining natural flow:"""

    fixed_tokens = (string2token_nums(inst1 + inst2) +
                    string2token_nums("Summary:\n\nEvaluation:\nReason:\nNews article:\n\n") * len(examples) +
                    human_tokens + 50)

    all_abs_tokens = sum(string2token_nums(s["abstract"]) for s in examples)
    truncated_len = max(10, (4000 - fixed_tokens - all_abs_tokens) // (2 * len(examples)))

    prompt = inst1
    for s in examples:
        abs_truncated = truncate_text(s.get("abstract") or "", truncated_len, 'token')
        pre_gpt = (s.get("pre_gpt_news") or "").strip()
        pre_text = pre_gpt if pre_gpt else (s.get("machine_news") or "").strip()
        pre_type = "Previous round GPT result" if pre_gpt else "Machine-generated result"
        current_gpt = (s.get("gpt_news") or "").strip()

        metrics = s.get("metrics", {})
        pre_metrics = metrics.get("pre", {})
        current_metrics = metrics.get("current", {})

        metrics_data = {
            'bleu': (current_metrics.get('bleu', 0), pre_metrics.get('bleu', 0)),
            'meteor': (current_metrics.get('meteor', 0), pre_metrics.get('meteor', 0)),
            'rouge_l': (current_metrics.get('rouge_l', 0), pre_metrics.get('rouge_l', 0)),
            'bert_score': (current_metrics.get('bert_score', 0), pre_metrics.get('bert_score', 0)),
            'g_eval': (current_metrics.get('g_eval', 0), pre_metrics.get('g_eval', 0))
        }

        metric_str = "Comparison metrics:\n"
        for name, (current, pre) in metrics_data.items():
            metric_str += f"- {name.upper()}: Current {current:.2f} vs {pre_type} {pre:.2f}\n"

        optimization_hints = []
        if metrics_data['bleu'][0] < metrics_data['bleu'][1] - 0.03:
            optimization_hints.append("Improve word choice to match human writing style (focus on n-gram overlap)")
        if metrics_data['rouge_l'][0] < metrics_data['rouge_l'][1] - 0.03:
            optimization_hints.append("Adjust sentence structure to better align with key information sequence in human news")
        if metrics_data['meteor'][0] < metrics_data['meteor'][1] - 0.03:
            optimization_hints.append("Enhance semantic matching using synonyms and paraphrasing where appropriate")
        if metrics_data['bert_score'][0] < metrics_data['bert_score'][1] - 0.03:
            optimization_hints.append("Strengthen contextual consistency with the original summary")
        if metrics_data['g_eval'][0] < metrics_data['g_eval'][1] - 0.03:
            optimization_hints.append("Improve overall quality including fluency, coherence and relevance")

        optimization_str = "Optimization directions:\n"
        if optimization_hints:
            optimization_str += "\n".join([f"- {hint}" for hint in optimization_hints])
        else:
            optimization_str += "- Maintain current quality level across all metrics"

        prompt += f"Summary: {abs_truncated}\n"
        prompt += f"{pre_type}: {truncate_text(pre_text, truncated_len, 'token')}\n"
        prompt += f"Current GPT result: {truncate_text(current_gpt, truncated_len, 'token')}\n"
        prompt += f"{metric_str}\n"
        prompt += f"{optimization_str}\n"
        prompt += f"Evaluation: {s.get('evaluation', 'No evaluation')}\n\n"

    prompt += inst2
    return prompt, human_tokens

def make_detection_prompt(json_path, target_id):
    news_data = json2dict(json_path)
    news_dict = {str(item['id']): item for item in news_data}
    target_id_str = str(target_id)

    if target_id_str not in news_dict:
        raise ValueError(f"ID {target_id} not found")

    target_news = news_dict[target_id_str]
    example_ids = target_news.get("similar", [])
    if not isinstance(example_ids, list) or len(example_ids) < 5:
        raise ValueError(f"Insufficient similar IDs for {target_id}")

    examples = [news_dict[id] for id in example_ids]
    return example_ids, make_prompt_for_evaluation(examples, target_news)


def make_attacking_prompt(json_path, target_id):
    news_data = json2dict(json_path)
    news_dict = {str(item.get("id")): item for item in news_data}
    target_id_str = str(target_id)

    if target_id_str not in news_dict:
        raise ValueError(f"ID {target_id} not found")

    target_news = news_dict[target_id_str]
    example_ids = target_news.get("similar", [])
    if not isinstance(example_ids, list) or len(example_ids) < 5:
        raise ValueError(f"Insufficient similar IDs for {target_id}")

    examples = [news_dict[id] for id in example_ids]
    return example_ids, make_prompt_for_attacking(
        examples,
        target_news.get("abstract", ""),
        target_news.get("human_news", ""),
        json_path
    )[0]