"""
@filename:prompt.py
@author:Stmxlt
@time:2025-10-17
"""


import tiktoken
import json
import os
import threading
from typing import Any, Dict, List, Tuple, Optional
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from utils.per_news_evaluation import PerNewsEvaluation, get_per_news_improvement_suggestions

gpt_turbo_encoding = tiktoken.get_encoding("cl100k_base")
MODEL = SentenceTransformer("./local_models/all-MiniLM-L6-v2")
file_lock = threading.Lock()


def json2dict(path: str):
    with file_lock:
        if not os.path.exists(path):
            raise FileNotFoundError(f"File not found: {path}")
        if os.path.getsize(path) == 0:
            raise ValueError(f"Empty file: {path}")
        try:
            with open(path, "rt", encoding="utf-8") as f:
                content = f.read().strip()
                return json.loads(content) if content else []
        except json.JSONDecodeError as e:
            raise ValueError(f"JSON decode error in {path}: {str(e)}") from e


def dict2json(data, path: str):
    with file_lock:
        try:
            json_str = json.dumps(data, ensure_ascii=False, indent=2)
            with open(path, "wt", encoding="utf-8") as f:
                f.write(json_str)
        except Exception as e:
            raise ValueError(f"Failed to write JSON to {path}: {str(e)}") from e


def top5_similar(target_id, json_path: str):
    raw = json2dict(json_path)
    groups = []
    for g in raw:
        if "id" in g and "abstract" in g:
            groups.append({"id": str(g["id"]), "abstract": g["abstract"]})
        else:
            raise ValueError("Missing 'id' or 'abstract' in JSON entry")

    id_to_abs = {g["id"]: g["abstract"] for g in groups}
    target_id = str(target_id)
    if target_id not in id_to_abs:
        raise ValueError(f"ID {target_id} not found")

    target_abs = id_to_abs[target_id]
    others = [g for g in groups if g["id"] != target_id]
    texts = [target_abs] + [g["abstract"] for g in others]
    embs = MODEL.encode(texts, convert_to_tensor=False)
    sims = cosine_similarity([embs[0]], embs[1:])[0]

    scored = [{"id": g["id"], "score": float(s)} for g, s in zip(others, sims)]
    scored.sort(key=lambda x: x["score"], reverse=True)
    return scored[:5]


def top5_ids_only(target_id, json_path: str):
    return [item["id"] for item in top5_similar(target_id, json_path)]


def truncate_text(text: str, truncated_length: int, truncate_type: str):
    if truncate_type == "token":
        truncated_encodes = gpt_turbo_encoding.encode(text)[:truncated_length]
        return gpt_turbo_encoding.decode(truncated_encodes)
    elif truncate_type == "word":
        return " ".join(text.split(" ")[:truncated_length])
    else:
        return text


def string2token_nums(string: str) -> int:
    return len(gpt_turbo_encoding.encode(string))


def make_prompt_for_evaluation(examples: List[Dict[str, Any]], target_news: Dict[str, Any], max_tokens: int = 8192) -> str:
    evaluation_criteria = """Please evaluate the quality of news articles generated by LLM from news summaries, using human-written news as the standard. Assess from the following aspects and provide revision suggestions:

1. Title requirements:
- Accurately summarize the theme: Whether the title precisely matches the core theme of the news.
- Conciseness: Whether the title is concise, without redundancy, and expresses meaning efficiently.
- Precision of expression: Whether the wording and grammar of the title are accurate, avoiding ambiguity.

2. Lead requirements:
- Closeness to the theme: Whether the lead quickly anchors the core theme of the news.
- Conciseness: Whether the lead uses concise language to introduce information.

3. Body requirements:
- Clarity of theme: Whether the overall text of the body always revolves around the core theme.
- Completeness of information: Whether the body text fully conveys key news information (such as time, location, events and other core elements).
- Clarity of hierarchy: Whether the paragraph division and logical hierarchy of the body text are clear and easy to read.
- Fluency of writing: Whether the sentence connection and expression of the body text are natural and smooth, providing a smooth reading experience.

4. Conclusion requirements:
- Closeness to the theme: Whether the conclusion echoes the theme and effectively concludes the core content.
- Conciseness: Whether the conclusion is concise and powerful, avoiding procrastination and redundancy.

Please refer to the differences between human-written news and LLM news in the following examples, then for the LLM news to be evaluated, provide specific revision suggestions for each of the above aspects."""

    criteria_tokens = string2token_nums(evaluation_criteria)
    example_format = "Example X:\nNews summary:\nHuman-written news:\nLLM news:\n"
    example_format_tokens = string2token_nums(example_format) * len(examples)
    target_format = "News to be evaluated:\nNews summary:\nHuman-written news:\nLLM news:\n"
    target_format_tokens = string2token_nums(target_format)
    total_fixed_tokens = criteria_tokens + example_format_tokens + target_format_tokens

    remaining_tokens = max_tokens - total_fixed_tokens
    if remaining_tokens < 0:
        raise ValueError("Evaluation criteria exceed max token limit")

    per_part_tokens = remaining_tokens // 18
    if per_part_tokens < 10:
        raise ValueError("Insufficient tokens for valid prompt")

    prompt = evaluation_criteria + "\n\n"
    for i, example in enumerate(examples):
        prompt += f"Example{i + 1}:\n"
        abstract = truncate_text(example["abstract"], per_part_tokens, "token")
        human_news = truncate_text(example["human_news"], per_part_tokens, "token")

        pre_gpt_news = (example.get("pre_gpt_news") or "").strip()
        machine_news = (example.get("machine_news") or "").strip()
        llm_news = truncate_text(pre_gpt_news if pre_gpt_news else machine_news, per_part_tokens, "token")
        llm_type = "Previous round GPT result" if pre_gpt_news else "Machine-generated result"

        prompt += f"News summary: {abstract}\n"
        prompt += f"Human-written news: {human_news}\n"
        prompt += f"{llm_type}: {llm_news}\n\n"

    prompt += "News to be evaluated:\n"
    target_abstract = truncate_text(target_news["abstract"], per_part_tokens, "token")
    target_human = truncate_text(target_news["human_news"], per_part_tokens, "token")

    target_pre_gpt = (target_news.get("pre_gpt_news") or "").strip()
    target_machine = (target_news.get("machine_news") or "").strip()
    target_llm = truncate_text(target_pre_gpt if target_pre_gpt else target_machine, per_part_tokens, "token")
    target_llm_type = "Previous round GPT result" if target_pre_gpt else "Machine-generated result"

    prompt += f"News summary: {target_abstract}\n"
    prompt += f"Human-written news: {target_human}\n"
    prompt += f"{target_llm_type}: {target_llm}\n\n"
    prompt += "Please provide specific revision suggestions for the above LLM-generated news based on the evaluation criteria."
    return prompt


def _latest_completed_iteration_for_news(per_news_evaluator: PerNewsEvaluation, news_id: str, max_iter: int) -> Optional[int]:
    """
    Find the latest iteration <= max_iter that has stored metrics for this news_id.
    This avoids using the current iteration before it's evaluated/stored.
    """
    if max_iter <= 0:
        return None
    for it in range(max_iter, 0, -1):
        m = per_news_evaluator.get_iteration_metrics(it, news_id)
        if isinstance(m, dict) and m:
            return it
    return None


def make_prompt_for_attacking(
    examples: List[Dict[str, Any]],
    target_abstract: str,
    target_human_news: str,
    json_path: str,
    iteration: int,
):
    # --- Length target (word-based) ---
    human_words = len((target_human_news or "").split())
    # Safety floor to avoid too tiny targets when human is very short
    low_words = max(120, int(human_words * 0.85))
    high_words = max(low_words + 40, int(human_words * 1.15))  # keep a reasonable band

    # Keep existing token usage for budgeting
    human_tokens = string2token_nums(target_human_news)

    inst1 = f"""You are an expert news writer. Below are examples of high-quality news articles generated from similar summaries, showing benchmark texts, current outputs, and metric comparisons.

Study these examples carefully, noting:
- Vocabulary choices that match reference texts (for BERTScore)
- Sentence structures and sequence patterns (for SMS)
- Overall similarity and style (for GPTScore)
- Multi-dimensional quality (for G-Eval: consistency, fluency, coherence, relevance)

Examples:
{{examples}}
"""

    # --- Updated inst2: word target + non-factual expansion allowed ---
    inst2 = f"""Generate a news article for the new summary following these specific guidelines:

**PRIMARY OBJECTIVE:**
- Write in a human-journalistic style that closely matches the human-written exemplar articles.
- The summary is the ONLY factual source. Style should come from exemplars, not from the summary’s wording.

**LENGTH TARGET (IMPORTANT):**
- Target length: {low_words}–{high_words} words (roughly matching the human-written article length).
- If you are under the range, expand ONLY with non-factual journalistic writing (see ALLOWED NON-FACTUAL EXPANSION), NOT with new facts.
- If you are over the range, remove redundancy while keeping all summary-supported facts.

**CONTENT REQUIREMENTS:**
1. **Title**:
   - Include the key entities and the main action/event from the summary
   - Prefer natural headline phrasing similar to the exemplars (do not force-copy summary wording)

2. **Lead**:
   - Answer Who, What, When, Where concisely (and only if supported by the summary)
   - Use a natural, human news lead style similar to exemplars
   - Do NOT mechanically reuse summary phrases; paraphrase is allowed as long as meaning is preserved

3. **Body**:
   - First paragraph: Expand the lead with the most important supporting details from the summary
   - Middle paragraphs: Elaborate by reorganizing, clarifying, and connecting ONLY the summary-supported facts
   - Use transitional phrases for coherence, matching exemplar flow
   - Include specific numbers, dates, and attributions exactly as in the summary when present
   - Keep the narrative coherent and non-redundant; avoid template-like patterns

4. **Conclusion**:
   - Summarize the key impact or next steps ONLY if supported by the summary
   - Keep an objective news tone; avoid speculation

**ALLOWED NON-FACTUAL EXPANSION (DO NOT ADD FACTS):**
You MAY extend length by adding:
- Journalistic transitions and framing (e.g., “In a statement, ...”, “The announcement follows ...”, “The development comes as ...”)
- Clear paraphrases and restatements of summary facts in different wording (same meaning, no new facts)
- Discourse glue: chronology markers, contrast, emphasis, sentence-to-sentence logical links
- Neutral attribution scaffolding ONLY if the summary already contains attribution (do not invent sources)

You MUST NOT add:
- Any new entities, numbers, dates, locations, causes, consequences, motivations, or background not in the summary
- Any specific historical context unless explicitly stated in the summary
- Any new quotes or claims not present in the summary

**STYLE GUIDELINES:**
- Preserve proper nouns, named entities, technical terms, numbers, dates, and quoted/attributed statements exactly as in the summary
- Do NOT introduce new facts, background knowledge, or opinions beyond the summary
- Maintain formal, professional news writing tone throughout
- Vary sentence length naturally, but stay within the LENGTH TARGET
- Ensure each sentence logically follows the previous one, with human-like flow

**OPTIMIZATION TARGETS:**
- Factual grounding: 100% of facts must align with the summary; no added facts
- Human-likeness: Sentence structure, discourse organization, and phrasing should resemble the exemplars
- Lexical flexibility: Do not optimize for high word overlap; paraphrase is allowed if meaning is preserved
- Readability: Clear, professional, and engaging

New summary: {target_abstract}

Generate the news article now. Output only the news article:"""

    fixed_tokens = (
        string2token_nums(inst1 + inst2)
        + string2token_nums("Summary:\n\nEvaluation:\nReason:\nNews article:\n\n") * len(examples)
        + human_tokens
        + 50
    )

    all_abs_tokens = sum(string2token_nums(s.get("abstract", "") or "") for s in examples)
    BUDGET = 12000
    truncated_len = max(50, (BUDGET - fixed_tokens - all_abs_tokens) // (2 * len(examples)))

    per_news_evaluator = PerNewsEvaluation()

    # Use latest completed iteration for suggestions (<= iteration-1)
    max_iter_for_suggestion = max(1, iteration - 1)

    blocks = []
    for s in examples:
        abs_truncated = truncate_text(s.get("abstract") or "", truncated_len, "token")
        pre_gpt = (s.get("pre_gpt_news") or "").strip()
        pre_text = pre_gpt if pre_gpt else (s.get("machine_news") or "").strip()
        pre_type = "Previous round GPT result" if pre_gpt else "Machine-generated result"
        current_gpt = (s.get("gpt_news") or "").strip()
        if not current_gpt:
            current_gpt = (s.get("pre_gpt_news") or s.get("machine_news") or "").strip()

        news_id = str(s.get("id", "")).strip()

        # Find latest completed metrics iteration for this news
        last_it = _latest_completed_iteration_for_news(per_news_evaluator, news_id, max_iter_for_suggestion)

        if last_it is not None:
            suggestions = get_per_news_improvement_suggestions(news_id, last_it, per_news_evaluator)
        else:
            suggestions = {"message": "No previous iteration metrics available for this news item."}

        metrics = s.get("metrics", {})
        pre_metrics = metrics.get("pre", {})
        current_metrics = metrics.get("current", {})

        metrics_data = {
            "bert_score": (current_metrics.get("bert_score", 0), pre_metrics.get("bert_score", 0)),
            "sms": (current_metrics.get("sms", 0), pre_metrics.get("sms", 0)),
            "gptscore": (current_metrics.get("gptscore", 0), pre_metrics.get("gptscore", 0)),
            "g_eval_coherence": (current_metrics.get("g_eval_coherence", 0), pre_metrics.get("g_eval_coherence", 0)),
            "g_eval_consistency": (current_metrics.get("g_eval_consistency", 0), pre_metrics.get("g_eval_consistency", 0)),
            "g_eval_fluency": (current_metrics.get("g_eval_fluency", 0), pre_metrics.get("g_eval_fluency", 0)),
            "g_eval_relevance": (current_metrics.get("g_eval_relevance", 0), pre_metrics.get("g_eval_relevance", 0)),
        }

        metric_str = "Comparison Metrics:\n"
        for name, (cur, pre) in metrics_data.items():
            metric_str += f"- {name.upper()}: Current {cur:.2f} vs {pre_type} {pre:.2f}\n"

        optimization_str = "Personalized Optimization Directions:\n"
        if suggestions and "message" not in suggestions:
            optimization_str += "\n".join([f"- {hint}" for hint in suggestions.values()])
        else:
            optimization_str += "- Maintain current performance across all evaluation metrics"

        block = (
            f"Summary: {abs_truncated}\n"
            f"{pre_type}: {truncate_text(pre_text, truncated_len, 'token')}\n"
            f"Current GPT result: {truncate_text(current_gpt, truncated_len, 'token')}\n"
            f"{metric_str}\n"
            f"{optimization_str}\n"
            f"Evaluation: {s.get('evaluation', 'No evaluation')}\n\n"
        )
        blocks.append(block)

    prompt = inst1.replace("{examples}", "".join(blocks)) + "\n" + inst2
    return prompt, human_tokens



def make_detection_prompt(json_path: str, target_id):
    news_data = json2dict(json_path)
    news_dict = {str(item["id"]): item for item in news_data}
    target_id_str = str(target_id)

    if target_id_str not in news_dict:
        raise ValueError(f"ID {target_id} not found")

    target_news = news_dict[target_id_str]
    example_ids = target_news.get("similar", [])
    if not isinstance(example_ids, list) or len(example_ids) < 5:
        raise ValueError(f"Insufficient similar IDs for {target_id}")

    examples = [news_dict[_id] for _id in example_ids]
    return example_ids, make_prompt_for_evaluation(examples, target_news)


def make_attacking_prompt(json_path: str, target_id, iteration: int):
    news_data = json2dict(json_path)
    news_dict = {str(item.get("id")): item for item in news_data}
    target_id_str = str(target_id)

    if target_id_str not in news_dict:
        raise ValueError(f"ID {target_id} not found")

    target_news = news_dict[target_id_str]
    example_ids = target_news.get("similar", [])
    if not isinstance(example_ids, list) or len(example_ids) < 5:
        raise ValueError(f"Insufficient similar IDs for {target_id}")

    examples = [news_dict[_id] for _id in example_ids]
    prompt, _ = make_prompt_for_attacking(
        examples,
        target_news.get("abstract", ""),
        target_news.get("human_news", ""),
        json_path,
        iteration,
    )
    return example_ids, prompt
